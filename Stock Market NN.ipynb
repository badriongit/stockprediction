{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "iraqi-worse",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python program to implement a \n",
    "# single neuron neural network \n",
    "\n",
    "# import all necessery libraries \n",
    "from numpy import exp, array, random, dot, tanh\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "shaped-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_iterations = 1\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "liberal-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to create a neural \n",
    "# network with single neuron \n",
    "class NeuralNetwork(): \n",
    "    \n",
    "    def __init__(self): \n",
    "        \n",
    "        # Using seed to make sure it'll \n",
    "        # generate same weights in every run \n",
    "        random.seed(1) \n",
    "        \n",
    "        # 3x1 Weight matrix \n",
    "        self.weight_matrix = 2 * random.random((5, 1)) - 1\n",
    "        if(DEBUG):\n",
    "            print(f\"WEIGHT MATRIX: {self.weight_matrix}\")\n",
    "    # tanh as activation function \n",
    "    def tanh(self, x): \n",
    "        return tanh(x) \n",
    "\n",
    "    # derivative of tanh function. \n",
    "    # Needed to calculate the gradients. \n",
    "    def tanh_derivative(self, x): \n",
    "        return 1.0 - tanh(x) ** 2\n",
    "\n",
    "    # forward propagation \n",
    "    def forward_propagation(self, inputs):\n",
    "        dot_product = dot(inputs, self.weight_matrix)\n",
    "        if(DEBUG):\n",
    "            print(f\"DOT PRODUCT :{dot_product}\")\n",
    "        return self.tanh(dot_product) \n",
    "    \n",
    "    # training the neural network. \n",
    "    def train(self, train_inputs, train_outputs, \n",
    "                            num_train_iterations): \n",
    "                                \n",
    "        # Number of iterations we want to \n",
    "        # perform for this set of input. \n",
    "        for iteration in range(num_train_iterations): \n",
    "            #iteration for number of rows\n",
    "            for record in train_inputs:\n",
    "                if(DEBUG):\n",
    "                    print(f\"INPUT ROW: {record}\")\n",
    "\n",
    "                output = self.forward_propagation(record) \n",
    "                if(DEBUG):\n",
    "                    print(f\"OUTPUT ROW: {output}\")\n",
    "#                 # Calculate the error in the output. \n",
    "                error = train_outputs - output\n",
    "#                 # multiply the error by input and then \n",
    "#                 # by gradient of tanh funtion to calculate \n",
    "#                 # the adjustment needs to be made in weights \n",
    "                adjustment = dot(train_inputs.T, error * self.tanh_derivative(output)) \n",
    "#                 print('adjustment')\n",
    "#                 print(adjustment)                        \n",
    "#                 # Adjust the weight matrix \n",
    "                self.weight_matrix += adjustment \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "outdoor-technique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New weights after training\n",
      "[[ 101.85220329]\n",
      " [   5.07010478]\n",
      " [ 255.96518547]\n",
      " [ -43.71436189]\n",
      " [-253.04198915]]\n",
      "[[1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishnu/Documents/gitrepo/analysis_env/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/vishnu/Documents/gitrepo/analysis_env/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Driver Code \n",
    "if __name__ == \"__main__\": \n",
    "    \n",
    "    neural_network = NeuralNetwork() \n",
    "    \n",
    "#     print ('main:Random weights at the start of training') \n",
    "\n",
    "    #train_inputs = array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]]) \n",
    "    #train_outputs = array([[0, 1, 1, 0]]).T \n",
    "#     df = pd.read_csv ('E:\\\\GoogleDrive_sem1\\\\GoogleDrive_sem1\\\\sem 4\\\\project\\\\2019201015\\\\data\\\\combined_csv.csv')\n",
    "    df = pd.read_csv('combined_csv.csv')\n",
    "    \n",
    "    \n",
    "    #work = df[[\"Date\",\"Prev Close\",\"Open Price\",\"High Price\",\"Low Price\",\"Close Price\"]]\n",
    "    # preprocessing and normalization\n",
    "    work = df[[\"Date\",\"Prev Close\",\"Open Price\",\"High Price\",\"Low Price\",\"Close Price\"]]\n",
    "\n",
    "    work['O-C'] = work['Open Price'] - work['Close Price']\n",
    "    work['H-L'] = work['High Price'] - work['Low Price']\n",
    "    \n",
    "    \n",
    "    train_inputs=work[[\"Open Price\",\"High Price\",\"Low Price\",\"O-C\",\"H-L\"]]\n",
    "    train_outputs = work['Close Price']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_inputs, train_outputs, test_size=0.33)\n",
    "    \n",
    "    train_inputs=preprocessing.normalize(X_train)\n",
    "  \n",
    "    train_outputs = MinMaxScaler().fit_transform(array(y_train).reshape(-1,1)) \n",
    "    \n",
    "    # model training starts\n",
    "    neural_network.train(train_inputs, train_outputs, num_train_iterations) \n",
    "\n",
    "    print ('New weights after training') \n",
    "    print (neural_network.weight_matrix) \n",
    "\n",
    "#     # Test the neural network with a new situation. \n",
    "#     print (\"Testing network on new examples ->\") \n",
    "    testRecord = MinMaxScaler().fit_transform(array([2168,2183.9,2154,29.9,0.4]).reshape(-1,1))\n",
    "    print (neural_network.forward_propagation(testRecord.reshape(1,5))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
